{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Interesting Applications of AI: Experimenting with Elicit (GPT-3!)\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- image: images/elicit-icon.png\n",
    "- hide: false\n",
    "- categories: [gpt, elicit, ought]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What this Post is About\n",
    "\n",
    "A few months ago, I gained access to a new exciting tool called [Elicit](https://elicit.org/) from [Ought](https://ought.org/). Elicit is an AI research assistant that helps you answer questions \"by making qualitative reasoning steps explicit and using language models to incrementally automate those steps.\" \n",
    "\n",
    "Here we can see Elicit's main page, where I have on the Task picker. (Though it's hidden here, there is a text prompt box below the picker where you can type in a question, topic or sentence.)\n",
    "\n",
    "![View of Elicit tasks](https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/elicit-tasks.png)\n",
    "\n",
    "Using GPT-3 on the backend, Elicit is able to help with a wide range of research and brainstorming tasks. The team behind Elicit are focused on building tools that will help millions of people think through the types of questions we ask ourselves every day.\n",
    "\n",
    "You can watch [Elicit screencasts](https://www.youtube.com/channel/UCg5fl1Ht965Me_KuV84XFwg) on YouTube to get a sense of all the things it can do. It really is impressive.\n",
    "\n",
    "You can see below a video of Elicit being used to help researchers search for papers on the topic of military applications of AI, something that the [Center for Security and Emerging Technology](https://cset.georgetown.edu/) (CSET) is interested in and has done great work on.\n",
    "\n",
    "\n",
    "> youtube: https://youtu.be/xs1MdYczchM\n",
    "\n",
    "\n",
    "What's amazing about this video is that Xavier Amatriain says that GPT-3 was better at creating labeled data for their models than anything they could have come up with themselves. Part of the reason is that GPT-3 was actually capable of generating not only much more data, but also much more diverse (nuanced variability) data.\n",
    "\n",
    "So, in fact, what you could do is create an active learning process along with GPT-3 to label the data, and as more quality data becomes available, you can even fine-tune a pre-trained model on that generated data (which is what Curai seems to be doing).\n",
    "\n",
    "## What Excites me about Tools like Elicit\n",
    "\n",
    "Recent innovations in machine learning have helped us build models which are great at dealing with labeled data tasks, but how can we use these models to answer questions where we don't have a labeled dataset and are a bit more subjective? For example, could we have an AI where we can ask it questions like \"How do I decide what career I should dedicate my life to?\" or \"My partner feels jealous about my career growth, what should I do?\" It would really be amazing if we could have an AI that could answer these questions.\n",
    "\n",
    "I'm particularly excited about how AI will help make knowledge accessible to everyone in a way that will guide humanity towards a better future. Though still in its early stages, AI has started showing signs of having the potential to revolutionize education, research, and even therapy. \n",
    "\n",
    "One glimpse of this was in a Twitter thread where one of the employees at OpenAI said they used GPT-3 as a therapist and were able to achieve a deeper breakthrough than they had ever had with a human therapist. We're not at the point where our models can be taken out of the labs yet, but once our models become exceptional and robust, and we can make such fields unbelievably cheap, accessible, and compatible with human values, inequality of world-class services will likely change quickly.\n",
    "\n",
    "## My Initial look into Elicit\n",
    "\n",
    "For this blog post, I will focus on giving an overview of Elicit rather than going into the nitty-gritty. I'm not going to be too formal and will instead point to some of the things I find cool and just give my thoughts.\n",
    "\n",
    "Going back to AI for mental health, we can see here how Elicit is used to help do Positive Reframing of negative statements you tell it. The video below shows how they give Elicit prompts for Few-Shot Learning. If you simply ask GPT-3 a question without any prompts, we call it a \"Zero-Shot\" model. Once we give it one example (K=1), it becomes a \"One-Shot\" model. For more than one example (K=2+), we call it a \"few-shot\" model. Obviously, the more examples we give it, the more accurate it will be, but it can still give great results with very few examples. As we saw in the [original GPT-3 paper](https://arxiv.org/abs/2005.14165), as you increase K, GPT-3 can perform better than a model like BERT fine-tuned on a given task (scroll a bit to see a plot example from the paper). That is why it is useful to add examples in Elicit.\n",
    "\n",
    "\n",
    "> youtube: https://youtu.be/AIW5xM2VMaQ\n",
    "\n",
    "\n",
    "Here's a chart showing GPT-3 performance on a Trivia task:\n",
    "\n",
    "\n",
    "![gpt-3-vs-fine-tuned-sota-triviaqa.png](https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/gpt-3-vs-fine-tuned-sota-triviaqa.png)\n",
    "\n",
    "> On TriviaQA GPT3â€™s performance grows smoothly with model size, suggesting that language models continue to absorb knowledge as their capacity increases. One-shot and few-shot performance make significant gains over zero-shot behavior, matching and exceeding the performance of the SOTA fine-tuned open-domain model, RAG.\n",
    "\n",
    "This is exciting and all, but I should note that this not always the case and you need to be aware when a fine-tuned model trained on full training data will be better in your situation. As we can see in a recent [paper](https://arxiv.org/abs/2109.02555), GPT-3 does not mean the end of fine-tuned models:\n",
    "\n",
    "> We investigated the performance of two powerful transformer language models, i.e. GPT-3 and BioBERT, in few-shot settings on various biomedical NLP tasks. The experimental results showed that, to a great extent, both the models underperform a language model fine-tuned on the full training data. Although GPT-3 had already achieved near state-of-the-art results in few-shot knowledge transfer on open-domain NLP tasks, it could not perform as effectively as BioBERT, which is orders of magnitude smaller than GPT-3.\n",
    "\n",
    "That said, GPT-3 was created to be as good as possible to a whole variety of tasks with no fine-tuning, and it did not fall short of that.\n",
    "\n",
    "### The Use of Stars in Elicit\n",
    "\n",
    "You will notice by watching the videos that there are stars next to each output. Clicking on these stars help the underlying GPT-3 model become better at generating new output. In other words, my understanding is that they use the user-selected stars as additional prompts to the model, thereby increase K and making the few-shot model more accurate for the user.\n",
    "\n",
    "As you select stars, you can generate more output and get more of the kind of output you are looking for.\n",
    "\n",
    "What if none of the outputs are what you are looking for? Well, you can go to the bottom of the outputs and add a custom result to help the model out. After a few of these, you should be seeing better results.\n",
    "\n",
    "I think this is especially cool and it was implemented beautifully. A few months ago I was working on a project and trying to label a dataset using zero-shot learning, but I wasn't too impressed with the output. It really got me thinking about different ways we could use these kinds of models to help us label data. Depending on what we are trying to do, there are definitely a few approaches we could take. From using a library like [Snorkel](https://www.snorkel.org/), implementing an active learning component (an introduction can be found [here](https://livebook.manning.com/book/human-in-the-loop-machine-learning/chapter-1/58)), using a fine-tuned model for our specific task, or, of course, use GPT-like models to label data. One exceptional example of using GPT-3 to label data can be found here:\n",
    "\n",
    "\n",
    "> youtube: https://youtu.be/j_WMapKUsS4&t=1s\n",
    "\n",
    "\n",
    "### Into Forecasting?\n",
    "\n",
    "Elicit has a feature called [Elicit Forecast](https://forecast.elicit.org/binary?binaryQuestions.sortBy=popularity&limit=20&offset=0&predictors=community) which is hidden from the main website, but they go into a bit of detail about how it works in the video below. For any aspiring superforecaster out there, this could be a great tool.\n",
    "\n",
    "> youtube: https://youtu.be/eIxoj46UibY\n",
    "\n",
    "\n",
    "In the future, we can expect people will ask Elicit a question like, \"Will we be able to finish project x on time?\" and Elicit will give us its best guess. As time goes on, I'm sure a tool like Elicit will become an invaluable tool for not just forecasters, but also people like project managers who want to get a better idea on how long a project will actually take.\n",
    "\n",
    "### Building AI based on what we've Learned from Human Thinking\n",
    "\n",
    "There are concepts like First Principles Thinking (FTP) which have allowed humans to take great leaps in innovation. However, FTP is hard! We know how great it can be, yet few people use it habitually. Of course it's basically unsustainable to use for every little thing that we do. That's why even the people who do use FTP end up using it only when tackling hard problems. But what if we could lower the barrier to entry and sustainability for using FTP? What if we had an AI that allowed us to enter in to an \"FTP state of thinking\" more often and with higher effectiveness? Perhaps we could not only accelerate the work of great innovators, but also help those who never really got into an FTP state of thinking. I can see Elicit really helping in this direction.\n",
    "\n",
    "But here's what the people at Ought are already working on: generating subquestions and searching for answers to those subquestions!\n",
    "\n",
    "\n",
    "> youtube: https://youtu.be/hvITiQvrvtk\n",
    "\n",
    "This mode of thinking is something that was quite common when I was studying physics. And in fact, the physicist [Enrico Fermi](https://en.wikipedia.org/wiki/Enrico_Fermi) was known for, among many other things, using \"Fermi Estimates\" to make an educated guess about a question. Breaking down the main question into subquestions, he was able to answer the main question by creating estimates for the subquestions and feeding that into the main question. This method is now commonly used in forecasting and people will often run Monte Carlo simulations to get a guesstimate for each subquestion. I initially came across this idea in a more formal way in the book [How to Measure Anything by Douglas W. Hubbard](https://www.howtomeasureanything.com/).\n",
    "\n",
    "Anyway, as we see in that video, Elicit is able to generate subquestions to what seems to be an impossible question to answer. At the moment, the search results to help users answer the subquestions will be links to documents that may contain the answer. I believe they have made some progress since then, but I can see this going further in the future. For example, you could extract the text from a database of documents and use a model to actually answer the subquestion for the user and point to where exactly it found the answer in the document.\n",
    "\n",
    "In other words, you could have an open-ended question like \"How can we strengthen the US AI workforce?\" and Elicit could generate all the relevant subquestions and answer them! Beyond that, it could potentially help answer questions like \"How many professional piano tuners are there in Chicago?\" by answering a series of subquestions like \"What is the population of Chicago?\" and \"How many people in Chicago own a piano?\"\n",
    "\n",
    "I think it could even eventually end up doing a great job of answering questions like \"By 2070, how many climate refugees will there be in the US?\" by giving a nice probability distribution guesstimate with specific reasons for the output described.\n",
    "\n",
    "\n",
    "## Closing Thoughts\n",
    "\n",
    "Having worked in government for the past 4 years, there's a lot of things that excite me about Elicit, things that I thought of building myself. I'm glad someone is building a tool like this. \n",
    "\n",
    "As they write on their website, I can see it being applied in government policy (Senators could become better at asking questions and could get caught up to speed on issues much more effectively than the current approach), but I can also see it working in strategic foresight teams like [Policy Horizons Canada](https://horizons.gc.ca/en/home/) or in regulatory bodies (like the [Canada Energy Regulator](https://www.cer-rec.gc.ca/en/), my employer) who have to dig into tons of PDFs to find the right information and make sure the company is compliant with the law.\n",
    "\n",
    "I will note that one of the things I am the most excited for is creating a second brain with a tool like Elicit. Sure we can use Roam Research to connect our thoughts and we can even load tons of text in Roam Research, but I think Semantic Search with Elicit could be much more powerful by simply having it point to or answer questions we have on a certain topic after loading 100k documents on that topic."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8e9a18fee897584348f245f3ed6851049a290baafc4465fb2a04a303ae1e268b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}