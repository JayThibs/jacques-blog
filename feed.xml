<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://jacquesthibodeau.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jacquesthibodeau.com/" rel="alternate" type="text/html" /><updated>2021-09-30T09:34:30-05:00</updated><id>https://jacquesthibodeau.com/feed.xml</id><title type="html">Jacques Thibodeau</title><subtitle>Learn about building valuable AI solutions efficiently.</subtitle><entry><title type="html">How to Connect to VSCode to Colab</title><link href="https://jacquesthibodeau.com/deep-learning-setup/vscode/google-colab/2021/09/27/connect-to-colab-from-local-vscode.html" rel="alternate" type="text/html" title="How to Connect to VSCode to Colab" /><published>2021-09-27T00:00:00-05:00</published><updated>2021-09-27T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/deep-learning-setup/vscode/google-colab/2021/09/27/connect-to-colab-from-local-vscode</id><content type="html" xml:base="https://jacquesthibodeau.com/deep-learning-setup/vscode/google-colab/2021/09/27/connect-to-colab-from-local-vscode.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-27-connect-to-colab-from-local-vscode.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What-is-colab-ssh?&quot;&gt;What is colab-ssh?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-colab-ssh?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We'll be using the package called &lt;code&gt;colab-ssh&lt;/code&gt;. It's a package that uses either Cloudflare or Ngrok to connect to a Colab instance.&lt;/p&gt;
&lt;p&gt;This is NOT the same as using Codespaces in your browser, like the approach taken with &lt;code&gt;colabcode&lt;/code&gt;. For now, I much prefer using &lt;code&gt;colab-ssh&lt;/code&gt; because it allows me to use a local VSCode rather than one in the browser.&lt;/p&gt;
&lt;p&gt;I'll be using &lt;code&gt;colab-ssh&lt;/code&gt; for my own projects and see how it goes. It's a cheap way to do deep learning, but I'm still not certain if errors and timeouts will bug me enough to stop using it. I think it'll be fine, though! I'll likely use it just to run hyperparameter sweeps and other experiments. I think that's the ideal use for it.&lt;/p&gt;
&lt;p&gt;Now, let's get started. First we need to run code in Colab.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Code-we-need-to-run-in-Colab&quot;&gt;Code we need to run in Colab&lt;a class=&quot;anchor-link&quot; href=&quot;#Code-we-need-to-run-in-Colab&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;First we can mount our Google Drive so that we have access files or data that we need:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;google.colab&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drive&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;/content/drive&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This part is optional, but you can access a .env file in your Google Drive to access a &lt;code&gt;PASSWORD&lt;/code&gt; and &lt;code&gt;GITHUB_ACCESS_TOKEN&lt;/code&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;pip install python-dotenv --quiet
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dotenv&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dotenv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_dotenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;/content/drive/MyDrive/vscode-ssh&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;.env&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;PASSWORD&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;github_access_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;GITHUB_ACCESS_TOKEN&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here we will add the url to the github repo we would like to work on:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git_repo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;link_to_git_repo&amp;gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we can install &lt;code&gt;colab-ssh&lt;/code&gt; and import it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;pip install colab_ssh --upgrade --quiet
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;colab_ssh&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;launch_ssh_cloudflared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init_git_cloudflared&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Finally, we create the ssh connection and also add our github repo:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launch_ssh_cloudflared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;init_git_cloudflared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repository_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git_repo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;.git&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;personal_token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github_access_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;n&quot;&gt;branch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;lt;email_for_github&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;lt;github_username&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Setting-up-Cloudflared&quot;&gt;Setting up Cloudflared&lt;a class=&quot;anchor-link&quot; href=&quot;#Setting-up-Cloudflared&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;After that, you will get the following output:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/colab-ssh-output.png&quot; alt=&quot;colab-ssh-output&quot; /&gt;&lt;/p&gt;
&lt;p&gt;As it says in &quot;Client machine configuration&quot;, you will need to download &quot;cloudflared (Argo Tunnel)&quot; for your OS. I use Mac so that's the one I downloaded. I downloaded the latest version instead of using &lt;code&gt;brew install&lt;/code&gt; since that was faster.&lt;/p&gt;
&lt;p&gt;Anyways, go &lt;a href=&quot;https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation&quot;&gt;here&lt;/a&gt; and download the binary. Then, untar the file (or execute the .exe?) and then place the &lt;code&gt;cloudflared&lt;/code&gt; file in whatever local path you prefer.&lt;/p&gt;
&lt;h2 id=&quot;Setup-in-VSCode&quot;&gt;Setup in VSCode&lt;a class=&quot;anchor-link&quot; href=&quot;#Setup-in-VSCode&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Download Remote - SSH: go into VSCode and go to Extensions (CTRL+SHIFT+P), and search and click on &quot;Install Extension&quot;. Then, in Extensions, search and download &quot;Remote - SSH&quot;.&lt;/p&gt;
&lt;p&gt;Now that we have Remote - SSH, go into Command Palette (CTRL+SHIFT+P), and search and click on &quot;Remote - SSH: Open SSH Configuration File&quot;. This file is located at &lt;code&gt;~/.ssh/config&lt;/code&gt;. Go to that file and paste the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host *.trycloudflare.com
    HostName %h
    User root
    Port 22
    ProxyCommand &amp;lt;PUT_THE_ABSOLUTE_CLOUDFLARE_PATH_HERE&amp;gt; access ssh --hostname %h&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I'm assuming the port is 22 for everyone. If you have a different port, you can change it based on the output you received.&lt;/p&gt;
&lt;p&gt;Now, save the config file, copy the &quot;VSCode Remote SSH&quot; hostname from the Colab output, and paste it into the text box after clicking on &quot;Remote - SSH: Connect to Host...&quot;.&lt;/p&gt;
&lt;p&gt;There should be a new window that opens up.&lt;/p&gt;
&lt;p&gt;Click continue when a pop-up about a fingerprint appears and then type in the password you passed in to &lt;code&gt;launch_ssh_cloudflared&lt;/code&gt;. You are now fully connected via ssh!&lt;/p&gt;
&lt;p&gt;You can now access your GitHub repository via &quot;Open Folder&quot; in Explorer. I have not figured out how to changed the repository location yet, but for now, you will need to click on &lt;code&gt;..&lt;/code&gt; to exit /root/ and then click on &lt;code&gt;content&lt;/code&gt; and your repository should be there.&lt;/p&gt;
&lt;p&gt;You will get some cloudflared files added to the root of your repository, you can add them to your .gitignore file.&lt;/p&gt;
&lt;h2 id=&quot;Additional-Tips-to-Get-Started-Quickly&quot;&gt;Additional Tips to Get Started Quickly&lt;a class=&quot;anchor-link&quot; href=&quot;#Additional-Tips-to-Get-Started-Quickly&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Quick-Package-Installation&quot;&gt;Quick Package Installation&lt;a class=&quot;anchor-link&quot; href=&quot;#Quick-Package-Installation&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Once you've set things up, you just need to click Run All in Colab and it goes pretty fast. However, you will still need to reinstall all packages every time you create a new connection since Colab instances are ephemeral.&lt;/p&gt;
&lt;p&gt;I suggest you either create a &lt;code&gt;requirements.txt&lt;/code&gt; file, &lt;code&gt;environment.yml&lt;/code&gt; file, or you use a package like &lt;code&gt;poetry&lt;/code&gt; to get up and running quickly.&lt;/p&gt;
&lt;p&gt;Note for Conda: you need to run some extra code in colab in order to get access to conda in Colab. Follow the tutorial &lt;a href=&quot;https://towardsdatascience.com/conda-google-colab-75f7c867a522&quot;&gt;here&lt;/a&gt; if you really want to use conda. Personally, I would recommend against it since it takes longer to install. Try using pip, pip-tools or poetry instead.&lt;/p&gt;
&lt;p&gt;In my case, I create a Makefile for every project and then I simply need to enter &lt;code&gt;make poetry&lt;/code&gt; in the terminal. To create a Makefile, simply create a file called &lt;code&gt;Makefile&lt;/code&gt; in your project directory. Then, in the Makefile, you can add the following (or whatever installation commands you want for your specific dependency manager):&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Of course, you can use whatever package manager you prefer.&lt;/p&gt;
&lt;p&gt;And that's it! You are now ready to start coding!&lt;/p&gt;
&lt;h3 id=&quot;Use-only-one-Colab-Notebook&quot;&gt;Use only one Colab Notebook&lt;a class=&quot;anchor-link&quot; href=&quot;#Use-only-one-Colab-Notebook&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;To prevent having to create a notebook for every project, do the following to things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Do your package installations in VSCode rather than Colab. Then you only need to install the packages for a specific project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a cell in your Colab notebook with strings to your github repositories using &lt;code&gt;git_repo = &quot;git_repo_url&quot;&lt;/code&gt;. Just comment out the ones you don't want and uncomment the one you do.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This might sound obvious, but I started out by trying to install via Colab when I started out!&lt;/p&gt;
&lt;h2 id=&quot;Troubleshooting&quot;&gt;Troubleshooting&lt;a class=&quot;anchor-link&quot; href=&quot;#Troubleshooting&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;You-are-Asked-for-Username-and-Password&quot;&gt;You are Asked for Username and Password&lt;a class=&quot;anchor-link&quot; href=&quot;#You-are-Asked-for-Username-and-Password&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If you are asked for a username and password after launching the SSH connection, that means you are not passing in your GitHub personal access token into &lt;code&gt;init_git_cloudflared&lt;/code&gt;. Make sure to do that.&lt;/p&gt;
&lt;p&gt;You can setup your GitHub personal access token by clicking on your icon on the top right on GitHub, clicking on &quot;Settings&quot;, scroll down and click on &quot;Developer settings&quot;, and then clicking on &quot;Personal Access Tokens&quot;. Generate a new token and use it in &lt;code&gt;init_git_cloudflared&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;If-you-get:-&amp;quot;Could-not-establish-connection-to...&amp;quot;&quot;&gt;If you get: &quot;Could not establish connection to...&quot;&lt;a class=&quot;anchor-link&quot; href=&quot;#If-you-get:-&amp;quot;Could-not-establish-connection-to...&amp;quot;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This could mean a few things, so I'll go over the ones I encountered:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Your Remote - SSH config file is not correct.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Go to &quot;Remote - SSH: Settings&quot; and make sure that you are using the correct config file like the one below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/remote-ssh-settings-config.png&quot; alt=&quot;remote-ssh-settings-config&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Colab is still running &lt;code&gt;init_git_cloudflared&lt;/code&gt; because you did not pass it a valid personal access token.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;No-Access-to-GPU?&quot;&gt;No Access to GPU?&lt;a class=&quot;anchor-link&quot; href=&quot;#No-Access-to-GPU?&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Don't forget to go to Runtime &amp;gt; Change Runtime Type and select &quot;GPU&quot; in Colab!&lt;/p&gt;
&lt;h3 id=&quot;Can't-Find-Repository?&quot;&gt;Can't Find Repository?&lt;a class=&quot;anchor-link&quot; href=&quot;#Can't-Find-Repository?&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If you ran the code on a different repository and then you rerun it on a new repository, this may happen. Do resolve this, just do a factory reset of your Colab instance, and then rerun the code.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;That's-It!&quot;&gt;That's It!&lt;a class=&quot;anchor-link&quot; href=&quot;#That's-It!&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If you have any questions, let me know! Or better yet, go to the &lt;code&gt;colab-ssh&lt;/code&gt; repo and ask there!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="deep-learning-setup" /><category term="vscode" /><category term="google-colab" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/vscode-colab.jpeg" /><media:content medium="image" url="https://jacquesthibodeau.com/images/vscode-colab.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What I Learned from the Full Stack Deep Learning Labs</title><link href="https://jacquesthibodeau.com/deep-learning/full-stack-deep-learning/projects/2021/09/26/wil-from-fsdl-labs.html" rel="alternate" type="text/html" title="What I Learned from the Full Stack Deep Learning Labs" /><published>2021-09-26T00:00:00-05:00</published><updated>2021-09-26T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/deep-learning/full-stack-deep-learning/projects/2021/09/26/wil-from-fsdl-labs</id><content type="html" xml:base="https://jacquesthibodeau.com/deep-learning/full-stack-deep-learning/projects/2021/09/26/wil-from-fsdl-labs.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-26-wil-from-fsdl-labs.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What-are-the-Full-Stack-Deep-Learning-Labs-About?&quot;&gt;What are the Full Stack Deep Learning Labs About?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-are-the-Full-Stack-Deep-Learning-Labs-About?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="deep-learning" /><category term="full-stack-deep-learning" /><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/fsdl-icon.png" /><media:content medium="image" url="https://jacquesthibodeau.com/images/fsdl-icon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How to Fine-Tune GPT-3 via the OpenAI API</title><link href="https://jacquesthibodeau.com/gpt-3/openai/deep-learning/2021/09/26/fine-tuning-gpt-3.html" rel="alternate" type="text/html" title="How to Fine-Tune GPT-3 via the OpenAI API" /><published>2021-09-26T00:00:00-05:00</published><updated>2021-09-26T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/gpt-3/openai/deep-learning/2021/09/26/fine-tuning-gpt-3</id><content type="html" xml:base="https://jacquesthibodeau.com/gpt-3/openai/deep-learning/2021/09/26/fine-tuning-gpt-3.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-26-fine-tuning-gpt-3.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What-are-the-Full-Stack-Deep-Learning-Labs-About?&quot;&gt;What are the Full Stack Deep Learning Labs About?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-are-the-Full-Stack-Deep-Learning-Labs-About?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="gpt-3" /><category term="openai" /><category term="deep-learning" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/openai-gpt-3.jpg" /><media:content medium="image" url="https://jacquesthibodeau.com/images/openai-gpt-3.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Interesting Applications of AI - Elicit (GPT-3)</title><link href="https://jacquesthibodeau.com/gpt/elicit/ought/2021/09/24/experimenting-with-elicit.html" rel="alternate" type="text/html" title="Interesting Applications of AI - Elicit (GPT-3)" /><published>2021-09-24T00:00:00-05:00</published><updated>2021-09-24T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/gpt/elicit/ought/2021/09/24/experimenting-with-elicit</id><content type="html" xml:base="https://jacquesthibodeau.com/gpt/elicit/ought/2021/09/24/experimenting-with-elicit.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-24-experimenting-with-elicit.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;What-this-Post-is-About&quot;&gt;What this Post is About&lt;a class=&quot;anchor-link&quot; href=&quot;#What-this-Post-is-About&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;A few months ago, I gained access to a new exciting tool called &lt;a href=&quot;https://elicit.org/&quot;&gt;Elicit&lt;/a&gt; from &lt;a href=&quot;https://ought.org/&quot;&gt;Ought&lt;/a&gt;. Elicit is an AI research assistant that helps you answer questions &quot;by making qualitative reasoning steps explicit and using language models to incrementally automate those steps.&quot;&lt;/p&gt;
&lt;p&gt;Here we can see Elicit's main page, where I have on the Task picker. (Though it's hidden here, there is a text prompt box below the task selector where you can type in a question, topic or sentence.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/elicit-tasks.png&quot; alt=&quot;View of Elicit tasks&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Using GPT-3 on the backend, Elicit can help with a wide range of research and brainstorming tasks. The team behind Elicit is focused on building tools that will help millions of people think through the types of questions we ask ourselves every day.&lt;/p&gt;
&lt;p&gt;You can watch &lt;a href=&quot;https://www.youtube.com/channel/UCg5fl1Ht965Me_KuV84XFwg&quot;&gt;Elicit screencasts&lt;/a&gt; on YouTube to get a sense of all the things it can do. It is impressive.&lt;/p&gt;
&lt;p&gt;Here's a general overview of what Elicit can do:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Ppo7Pg-VCtA&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;You can see below a video of Elicit being used to help researchers search for papers on the topic of military applications of AI, something that the &lt;a href=&quot;https://cset.georgetown.edu/&quot;&gt;Center for Security and Emerging Technology&lt;/a&gt; (CSET) is interested in and has done great work on.

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/xs1MdYczchM&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;h2 id=&quot;What-Excites-me-about-Tools-like-Elicit&quot;&gt;What Excites me about Tools like Elicit&lt;a class=&quot;anchor-link&quot; href=&quot;#What-Excites-me-about-Tools-like-Elicit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Recent innovations in machine learning have helped us build models that deal with labeled data tasks, but how can we use these models to answer questions where we don't have a labeled dataset and are a bit more subjective? For example, could we have an AI where we can ask it questions like &quot;How do I decide what career I should dedicate my life to?&quot; or &quot;My partner feels jealous about my career growth, what should I do?&quot; It would be fantastic if we could have an AI that could answer these questions.&lt;/p&gt;
&lt;p&gt;I'm particularly excited about how AI will help make knowledge accessible to everyone in a way that will guide humanity towards a better future. Though still in its early stages, AI has started showing signs of having the potential to revolutionize education, research, and even therapy.&lt;/p&gt;
&lt;p&gt;One glimpse of this was in a Twitter thread where one of the employees at OpenAI said they used GPT-3 as a therapist and achieved a more profound breakthrough than they had ever had with a human therapist. Of course, we're not at the point where our models can be taken out of the labs yet. However, once our models become exceptional and robust (and we can make such services unbelievably cheap, accessible, and compatible with human values), the inequality of world-class services will likely change quickly.&lt;/p&gt;
&lt;h2 id=&quot;Initial-look-into-Elicit&quot;&gt;Initial look into Elicit&lt;a class=&quot;anchor-link&quot; href=&quot;#Initial-look-into-Elicit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;For this blog post, I will focus on giving an overview of Elicit rather than going into the nitty-gritty. So, I'm not going to be too formal and will instead point to some of the things I find cool and give my thoughts.&lt;/p&gt;
&lt;p&gt;Going back to AI for mental health, we can see here how Elicit is used to help do Positive Reframing of negative statements you tell it. The video below shows how they give Elicit prompts for Few-Shot Learning. If you simply ask GPT-3 a question without any prompts, we call it a &quot;Zero-Shot&quot; model. Once we give it one example (K=1), it becomes a &quot;One-Shot&quot; model. For more than one example (K=2+), we call it a &quot;few-shot&quot; model. The more examples we give, the more accurate it will be, but it can still provide great results with very few examples. As we saw in the &lt;a href=&quot;https://arxiv.org/abs/2005.14165&quot;&gt;original GPT-3 paper&lt;/a&gt;, as you increase K, GPT-3 can perform better than a model like BERT fine-tuned on a given task (scroll a bit to see a plot example from the paper). That is why it is helpful to add examples in Elicit.

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/AIW5xM2VMaQ&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;Here's a chart showing GPT-3 performance on a Trivia task:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JayThibs/jacques-blog/master/images/gpt-3-vs-fine-tuned-sota-triviaqa.png&quot; alt=&quot;gpt-3-vs-fine-tuned-sota-triviaqa.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;On TriviaQA GPT3's performance grows smoothly with model size, suggesting that language models continue to absorb knowledge as their capacity increases. One-shot and few-shot performance make significant gains over zero-shot behavior, matching and exceeding the performance of the SOTA fine-tuned open-domain model, RAG.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is exciting and all, but I should note that this is not always the case, and you need to be aware when a fine-tuned model trained on full training data will be better in your situation. As we can see in a recent &lt;a href=&quot;https://arxiv.org/abs/2109.02555&quot;&gt;paper&lt;/a&gt;, GPT-3 does not mean the end of fine-tuned models.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;We investigated the performance of two powerful transformer language models, i.e. GPT-3 and BioBERT, in few-shot settings on various biomedical NLP tasks. The experimental results showed that, to a great extent, both the models underperform a language model fine-tuned on the full training data. Although GPT-3 had already achieved near state-of-the-art results in few-shot knowledge transfer on open-domain NLP tasks, it could not perform as effectively as BioBERT, which is orders of magnitude smaller than GPT-3.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That said, GPT-3 was created to be as good as possible to a whole variety of tasks with no fine-tuning, and it did not fall short of that.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Creating-a-Task-in-Elicit&quot;&gt;Creating a Task in Elicit&lt;a class=&quot;anchor-link&quot; href=&quot;#Creating-a-Task-in-Elicit&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Here's a video of how to create your own task in Elicit so that you can mold it for your specific needs.

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/lm118HUlof4&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;I won't go into the details here since the video is very comprehensive.&lt;/p&gt;
&lt;h3 id=&quot;The-Use-of-Stars-in-Elicit&quot;&gt;The Use of Stars in Elicit&lt;a class=&quot;anchor-link&quot; href=&quot;#The-Use-of-Stars-in-Elicit&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You will notice by watching the videos that there are stars next to each output. Clicking on these stars helps the underlying GPT-3 model become better at generating new output. In other words, my understanding is that they use the user-selected stars as additional prompts to the model, thereby increase K and making the few-shot model more accurate for the user.&lt;/p&gt;
&lt;p&gt;As you select stars, you can generate more output and get more of the kind of output you are looking for.&lt;/p&gt;
&lt;p&gt;What if none of the outputs are what you are looking for? Well, you can go to the bottom of the outputs and add a custom result to help the model out. After a few of these, you should see better results.&lt;/p&gt;
&lt;p&gt;I think this is incredibly cool, and it was implemented beautifully. A few months ago, I was working on a project and trying to label a dataset using zero-shot learning, but I wasn't too impressed with the output. It got me thinking about different ways to use these models to help us label data. Depending on what we are trying to do, there are a few approaches we could take. From using a library like &lt;a href=&quot;https://www.snorkel.org/&quot;&gt;Snorkel&lt;/a&gt;, implementing an active learning component (an introduction can be found &lt;a href=&quot;https://livebook.manning.com/book/human-in-the-loop-machine-learning/chapter-1/58&quot;&gt;here&lt;/a&gt;), using a fine-tuned model for our specific task, or, of course, use GPT-like models to label data. One exceptional example of using GPT-3 to label data can be found here:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/j_WMapKUsS4&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;What's awesome about this video is that Xavier Amatriain says that GPT-3 was better at creating labeled data for their models than anything they could have come up with themselves. Part of the reason is that GPT-3 could generate not only much more data but also much more diverse (nuanced variability) data.&lt;/p&gt;
&lt;p&gt;So, you could create an active learning process along with GPT-3 to label the data, and as more quality data becomes available, you can even fine-tune a pre-trained model on that generated data (which is what Curai seems to be doing).&lt;/p&gt;
&lt;h3 id=&quot;Creating-a-Search-Task-in-Elicit&quot;&gt;Creating a Search Task in Elicit&lt;a class=&quot;anchor-link&quot; href=&quot;#Creating-a-Search-Task-in-Elicit&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In this video, we can see how we can use investment data to create a search task. For example, we can imagine VCs using Elicit to search for companies they might be interested in investing in. There's also a &quot;Composite&quot; task type (Compose multiple task types together into one). We could imagine a VC firm could create a search task that answers questions about the companies and then consolidate the companies that meet specific criteria.

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/_3AruJ3L6F0&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;h3 id=&quot;Using-Elicit-as-a-Researcher&quot;&gt;Using Elicit as a Researcher&lt;a class=&quot;anchor-link&quot; href=&quot;#Using-Elicit-as-a-Researcher&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;As was alluded to earlier, Ought puts a lot of effort into helping researchers conduct research. This can range from:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finding the best papers in a given field&lt;/li&gt;
&lt;li&gt;Generating research questions&lt;/li&gt;
&lt;li&gt;Identifying the most important sentence in an abstract to help quickly answer whether the paper is relevant or not&lt;/li&gt;
&lt;li&gt;Finding research collaborators&lt;/li&gt;
&lt;li&gt;Explaining a concept very simply or in terms you would better understand (ex: explain this economics concept in computer science terms)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's a video that shows how to create a list of potential research collaborators quickly:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/lI-sTOL9_K8&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;And here's a video where Elicit suggests which concepts you should focus on learning about to get a better understanding of a topic:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/eqPhAOnnXdU&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;This is one of the best ways I've found to better understand a topic/field very quickly, at least to the point where you can have a conversation with other experts in the field. We can imagine that people who need to grasp many concepts can significantly benefit from this task in Elicit. For example, VCs trying to grasp new technologies, politicians trying to understand something like Cryptocurrency, or interdisciplinary researchers trying to connect multiple fields.&lt;/p&gt;
&lt;h3 id=&quot;Into-Forecasting?&quot;&gt;Into Forecasting?&lt;a class=&quot;anchor-link&quot; href=&quot;#Into-Forecasting?&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Elicit has a feature called &lt;a href=&quot;https://forecast.elicit.org/binary?binaryQuestions.sortBy=popularity&amp;amp;limit=20&amp;amp;offset=0&amp;amp;predictors=community&quot;&gt;Elicit Forecast&lt;/a&gt; which is hidden from the main website, but they go into a bit of detail about how it works in the video below. For any aspiring superforecaster out there, this could be a great tool.

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/eIxoj46UibY&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;In the future, we can expect people will ask Elicit a question like, &quot;Will we be able to finish project x on time?&quot; and Elicit will give us its best guess. As time goes on, I'm sure a tool like Elicit will become an invaluable tool for forecasters and people like project managers who want to get a better idea of how long a project will take.&lt;/p&gt;
&lt;h3 id=&quot;Building-AI-based-on-what-we've-Learned-from-Human-Thinking&quot;&gt;Building AI based on what we've Learned from Human Thinking&lt;a class=&quot;anchor-link&quot; href=&quot;#Building-AI-based-on-what-we've-Learned-from-Human-Thinking&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;There are concepts like First Principles Thinking (FTP) that have allowed humans to take great leaps in innovation. However, FTP is hard! We know how great it can be, yet few people use it habitually. Of course, it's basically unsustainable to use for every little thing that we do. That's why even the people who use FTP end up using it only when tackling complex (many moving parts with feedback loops) or complicated (very difficult like building a rocket ship) problems. But what if we could lower the barrier to entry and sustainability for using FTP? What if we had an AI that allowed us to enter into an &quot;FTP state of thinking&quot; more often and with higher effectiveness? Perhaps we could accelerate the work of great innovators and help those who never really got into an FTP state of thinking. I can see Elicit helping in this direction.&lt;/p&gt;
&lt;p&gt;But here's what the people at Ought are already working on: generating subquestions and searching for answers to those subquestions!

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/hvITiQvrvtk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;This mode of thinking was quite common when I was studying physics. And in fact, the physicist &lt;a href=&quot;https://en.wikipedia.org/wiki/Enrico_Fermi&quot;&gt;Enrico Fermi&lt;/a&gt; was known for, among many other things, using &quot;Fermi Estimates&quot; to make an educated guess about a question. Breaking down the main question into subquestions, he answered the main question by creating estimates for the subquestions and feeding that into the main question. This method is now commonly used in forecasting, and people will often run Monte Carlo simulations to get a guesstimate for each subquestion. I initially came across this idea more formally in the book &lt;a href=&quot;https://www.howtomeasureanything.com/&quot;&gt;How to Measure Anything by Douglas W. Hubbard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, as we see in that video, Elicit can generate subquestions to what seems to be an impossible question to answer. At the moment, the search results to help users answer the subquestions will be linked to documents that may contain the answer. I believe they have made some progress since then, but I can see this going further in the future. For example, you could extract the text from a database of documents and use a model to actually answer the subquestion for the user and point to where exactly it found the answer in the document. (This may already be possible!)&lt;/p&gt;
&lt;p&gt;In other words, you could have an open-ended question like &quot;How can we strengthen the US AI workforce?&quot; and Elicit could generate all the relevant subquestions and answer them! Beyond that, it could potentially help answer questions like &quot;How many professional piano tuners are there in Chicago?&quot; by answering a series of subquestions like &quot;What is the population of Chicago?&quot; and &quot;How many people in Chicago own a piano?&quot;&lt;/p&gt;
&lt;p&gt;I think it could eventually end up doing a great job of answering questions like &quot;By 2070, how many climate refugees will there be in the US?&quot; by giving a nice probability distribution guesstimate with specific reasons for the output described.&lt;/p&gt;
&lt;h2 id=&quot;Closing-Thoughts&quot;&gt;Closing Thoughts&lt;a class=&quot;anchor-link&quot; href=&quot;#Closing-Thoughts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I've worked in government for the past four years, and many things excite me about Elicit, things that I thought of building myself. So I'm glad someone is building a tool like this.&lt;/p&gt;
&lt;p&gt;As they write on their website, I can see it being applied in government policy (Senators could become better at asking questions and could get caught up to speed on issues much more effectively than the current approach), but I can also see it working in strategic foresight teams like &lt;a href=&quot;https://horizons.gc.ca/en/home/&quot;&gt;Policy Horizons Canada&lt;/a&gt; or in regulatory bodies (like the &lt;a href=&quot;https://www.cer-rec.gc.ca/en/&quot;&gt;Canada Energy Regulator&lt;/a&gt;, my employer) who have to dig into tons of PDFs to find the right information and make sure the company is compliant with the law. Note: if you are interested about Strategic Foresight, I give an introduction &lt;a href=&quot;https://medium.com/@thibo.jacques/helping-organizations-survive-disasters-and-potentially-avoid-them-altogether-df9a4e835a90&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One of the things I am the most excited about is creating a second brain with a tool like Elicit. Sure we can use Roam Research to connect our thoughts, and we can even load tons of text in Roam Research. Still, I think Semantic Search with Elicit could be much more powerful by simply having it point to or answer questions we have on a specific topic after loading 100k documents on that topic. (And actually, I'm pretty sure this is already possible in Elicit, so I'll update this if I find out if it is!)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="gpt" /><category term="elicit" /><category term="ought" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/elicit-icon.png" /><media:content medium="image" url="https://jacquesthibodeau.com/images/elicit-icon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How to use Hugging Face and PyTorch Lightning on SageMaker</title><link href="https://jacquesthibodeau.com/mlops/huggingface/pytorchlightning/sagemaker/aws/2021/06/30/how-to-use-huggingface-and-pytorch-lightning-on-sagemaker.html" rel="alternate" type="text/html" title="How to use Hugging Face and PyTorch Lightning on SageMaker" /><published>2021-06-30T00:00:00-05:00</published><updated>2021-06-30T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/mlops/huggingface/pytorchlightning/sagemaker/aws/2021/06/30/how-to-use-huggingface-and-pytorch-lightning-on-sagemaker</id><content type="html" xml:base="https://jacquesthibodeau.com/mlops/huggingface/pytorchlightning/sagemaker/aws/2021/06/30/how-to-use-huggingface-and-pytorch-lightning-on-sagemaker.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-06-30-how-to-use-huggingface-and-pytorch-lightning-on-sagemaker.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This post will be put aside for now. It is quite easy to use HuggingFace with SageMaker now that Amazon and HuggingFace have made a partnership. You should only use HuggingFace with PyTorch Lightning after you've exhausted the more simple approaches that only involve HuggingFace (or if you really need a custom model, like a molti-modal model).&lt;/p&gt;
&lt;h1 id=&quot;Understanding-Model-Deployment-on-SageMaker&quot;&gt;Understanding Model Deployment on SageMaker&lt;a class=&quot;anchor-link&quot; href=&quot;#Understanding-Model-Deployment-on-SageMaker&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Before I dive into the nitty-gritty details of how to use Hugging Face and PyTorch Lightning in SageMaker, I'm going to give a general overview of SageMaker. In other words, &lt;strong&gt;if you only want to know how to use Hugging Face and PyTorch Lightning, skip this section.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;Quick-Overview-of-SageMaker&quot;&gt;Quick Overview of SageMaker&lt;a class=&quot;anchor-link&quot; href=&quot;#Quick-Overview-of-SageMaker&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;SageMaker allows AWS users to create a notebook instance in the cloud. SageMaker tries to make it easy for data scientists and machine learning engineers to train and deploy their machine learning models in production. Therefore, if you are comfortable using Jupyter Notebooks for data science, SageMaker will be great for you. However, there are some pros and cons.&lt;/p&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SageMaker has a great surrounding ecosystem that allows you to train, debug, and deploy your models, as well as my other useful tools for machine learning in production.&lt;/li&gt;
&lt;li&gt;It makes it easier to do some tests and sanity-checks when you are doing model development in the cloud.&lt;/li&gt;
&lt;li&gt;The SageMaker Python SDK makes it easy to do things like A/B tests. In other words, when you create or update an endpoint, you can easily split the traffic going to one endpoint across several models (and by different percentages/weights). You can easily change the endpoint configuration to switch to the best model over time.&lt;/li&gt;
&lt;li&gt;The SDK also makes it easy to load and unload models dynamically as needed (multi-model endpoints). If you use this in place of creating an endpoint for every model you put in production, you can save a heck of a lot of money. For example, if you have 1000 clients who all have a different model fine-tuned on their specific data, you can go from 171k to 1k US dollars per month!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS charges a premium for the usefulness of the notebook, and the surrounding infrastructure.&lt;/li&gt;
&lt;li&gt;Since you need to use the SageMaker Python SDK to run your code, your local notebooks need to be updated to run in SageMaker. That means, depending on the task, it may be preferable to simply put all your code in scripts, spin up an EC2 instance, and deploy with Docker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All-in-all, I would say that the best time to use SageMaker is when you are doing a lot of experimentation, you think notebooks will help you better explore the data, and you need to additional cloud compute resources.&lt;/p&gt;
&lt;p&gt;AWS also has a lot of sample notebooks for deployment, so it may be worth it to check them (particularly if you are planning to deploy similar models). Building on top of the work of others could also save you some time.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="mlops" /><category term="huggingface" /><category term="pytorchlightning" /><category term="sagemaker" /><category term="aws" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/made-with-ml.png" /><media:content medium="image" url="https://jacquesthibodeau.com/images/made-with-ml.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What I Learned From Made With ML MLOps Course</title><link href="https://jacquesthibodeau.com/mlops/madewithml/2021/06/29/what-i-learned-from-made-with-ml-mlops.html" rel="alternate" type="text/html" title="What I Learned From Made With ML MLOps Course" /><published>2021-06-29T00:00:00-05:00</published><updated>2021-06-29T00:00:00-05:00</updated><id>https://jacquesthibodeau.com/mlops/madewithml/2021/06/29/what-i-learned-from-made-with-ml-mlops</id><content type="html" xml:base="https://jacquesthibodeau.com/mlops/madewithml/2021/06/29/what-i-learned-from-made-with-ml-mlops.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-06-29-what-i-learned-from-made-with-ml-mlops.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;What-This-Post-Is-About&quot;&gt;What This Post Is About&lt;a class=&quot;anchor-link&quot; href=&quot;#What-This-Post-Is-About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;In this post, I will capture the learnings I made when going through the &lt;a href=&quot;https://madewithml.com/#mlops&quot;&gt;Made With ML MLOps&lt;/a&gt;. I will try to add my personal twist and I will skip over the section I already feel comfortable with, so you can go directly to the &lt;a href=&quot;https://madewithml.com&quot;&gt;Made With ML&lt;/a&gt; if you want to learn in more detail.&lt;/p&gt;
&lt;p&gt;My focus will be to give the TLDR of what I personally have learned the most from the website since that will be the most beneficial for me. That doesn't mean the things I don't cover are less important. For example, understanding intuition and the objective of a project is crucial and it is something I find many people will miss. If you're not aiming for the correct objective, everything else is basically meaningless.&lt;/p&gt;
&lt;p&gt;Anyway, without further ado, here are my notes from the MLOps course:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This is my first blog post on my website! Victory!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gifimage.net/wp-content/uploads/2017/11/final-fantasy-victory-gif-9.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;And more to come!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="mlops" /><category term="madewithml" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://jacquesthibodeau.com/images/made-with-ml.png" /><media:content medium="image" url="https://jacquesthibodeau.com/images/made-with-ml.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An Example Markdown Post</title><link href="https://jacquesthibodeau.com/markdown/2020/01/14/test-markdown-post.html" rel="alternate" type="text/html" title="An Example Markdown Post" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://jacquesthibodeau.com/markdown/2020/01/14/test-markdown-post</id><content type="html" xml:base="https://jacquesthibodeau.com/markdown/2020/01/14/test-markdown-post.html">&lt;h1 id=&quot;example-markdown-post&quot;&gt;Example Markdown Post&lt;/h1&gt;

&lt;h2 id=&quot;basic-setup&quot;&gt;Basic setup&lt;/h2&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-filename.md&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filename&lt;/code&gt; is whatever file name you choose, to remind yourself what this post is about. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.md&lt;/code&gt; is the file extension for markdown files.&lt;/p&gt;

&lt;p&gt;The first line of the file should start with a single hash character, then a space, then your title. This is how you create a &lt;em&gt;level 1 heading&lt;/em&gt; in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;## File names&lt;/code&gt; above.&lt;/p&gt;

&lt;h2 id=&quot;basic-formatting&quot;&gt;Basic formatting&lt;/h2&gt;

&lt;p&gt;You can use &lt;em&gt;italics&lt;/em&gt;, &lt;strong&gt;bold&lt;/strong&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;code font text&lt;/code&gt;, and create &lt;a href=&quot;https://www.markdownguide.org/cheat-sheet/&quot;&gt;links&lt;/a&gt;. Heres a footnote &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Heres a horizontal rule:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lists&quot;&gt;Lists&lt;/h2&gt;

&lt;p&gt;Heres a list:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And a numbered list:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;boxes-and-stuff&quot;&gt;Boxes and stuff&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is a quotation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;Toast Toast--warning googoo&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include alert boxes&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;div class=&quot;Toast&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include info boxes&lt;/span&gt;
&lt;/div&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/logo.png&quot; alt=&quot;&quot; title=&quot;fast.ai's logo&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;You can format text and code per usual&lt;/p&gt;

&lt;p&gt;General preformatted text:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Do a thing
do_thing()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python code and output:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Prints '2'
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as shell commands:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hello world&quot;&lt;/span&gt;
./some_script.sh &lt;span class=&quot;nt&quot;&gt;--option&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;value&quot;&lt;/span&gt;
wget https://example.com/cat_photo1.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as YAML:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;another_key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;another&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;value&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Column 1&lt;/th&gt;
      &lt;th&gt;Column 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A thing&lt;/td&gt;
      &lt;td&gt;Another thing&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;tweetcards&quot;&gt;Tweetcards&lt;/h2&gt;

&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Altair 4.0 is released! &lt;a href=&quot;https://t.co/PCyrIOTcvv&quot;&gt;https://t.co/PCyrIOTcvv&lt;/a&gt;&lt;br /&gt;Try it with:&lt;br /&gt;&lt;br /&gt;  pip install -U altair&lt;br /&gt;&lt;br /&gt;The full list of changes is at &lt;a href=&quot;https://t.co/roXmzcsT58&quot;&gt;https://t.co/roXmzcsT58&lt;/a&gt; ...read on for some highlights. &lt;a href=&quot;https://t.co/vWJ0ZveKbZ&quot;&gt;pic.twitter.com/vWJ0ZveKbZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jake VanderPlas (@jakevdp) &lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw&quot;&gt;December 11, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This is the footnote.&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Example Markdown Post</summary></entry></feed>